{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_Python_code_for_climatic_data_comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hgGZaPy9vA2e"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wyUOIo2vvA3c",
        "colab": {}
      },
      "source": [
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import gc\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from collections import Counter#<---value count for list\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MS-L5JZVvA3l",
        "colab": {}
      },
      "source": [
        "#Select the target species\n",
        "file_id=\"nutwoo\"\n",
        "bird_name=\"Nuttall's Woodpecker\"\n",
        "bcr_id='32'\n",
        "\n",
        "file_id=\"recwoo\"\n",
        "bird_name=\"Red-cockaded Woodpecker\"\n",
        "bcr_id='27'\n",
        "\n",
        "file_id=\"lewwoo\"\n",
        "bird_name=\"Lewis’s Woodpecker\"\n",
        "bcr_id='9 and 10'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WjAs-1HgvA3t",
        "colab": {}
      },
      "source": [
        "PATH='/content/drive/My Drive/Colab Notebooks/dissertation/'\n",
        "ebird_ss=pd.read_csv(PATH+'ebird_ss_'+file_id+'_add30yMonth.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVhFnX0veORO",
        "colab_type": "text"
      },
      "source": [
        "## Define useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GrUf85ygvNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        if col != 'time':\n",
        "            col_type = df[col].dtypes\n",
        "            if col_type in numerics:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)  \n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXcWTX1Ca_h",
        "colab_type": "text"
      },
      "source": [
        "## Drop/fix NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcGpJalcCH7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check\n",
        "print((ebird_ss.isna().describe().loc['unique']==2).sort_values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBhusA17CNv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if file_id==\"nutwoo\":\n",
        "    # For Nuttall's Woodpecker\n",
        "    print(ebird_ss.prec30_cv.isna().value_counts())\n",
        "    print(ebird_ss.prec180_cv.isna().value_counts())\n",
        "    print(ebird_ss.observation_count.isna().value_counts())\n",
        "    ebird_ss.loc[ebird_ss['prec30_cv'].isna(),'prec30_cv']=0\n",
        "    ebird_ss.loc[ebird_ss['prec180_cv'].isna(),'prec180_cv']=0\n",
        "    ebird_ss.drop(columns=['observation_count'],inplace=True)\n",
        "\n",
        "elif file_id==\"recwoo\":\n",
        "    # For \"Red-cockaded Woodpecker\"\n",
        "    print(ebird_ss.prec30_cv.isna().value_counts())\n",
        "    print(ebird_ss.elevation_median.isna().value_counts())\n",
        "    print(ebird_ss.elevation_sd.isna().value_counts())\n",
        "    print(ebird_ss.observation_count.isna().value_counts())\n",
        "    ebird_ss.drop(columns=['observation_count'],inplace=True)\n",
        "    ebird_ss.dropna(inplace=True)\n",
        "    ebird_ss.reset_index(drop=True,inplace=True)\n",
        "\n",
        "elif file_id==\"lewwoo\":\n",
        "    # For \"Lewis’s Woodpecker\"\n",
        "    print(ebird_ss.prec30_cv.isna().value_counts())\n",
        "    print(ebird_ss.observation_count.isna().value_counts())\n",
        "    ebird_ss.loc[ebird_ss['prec30_cv'].isna(),'prec30_cv']=0\n",
        "    ebird_ss.drop(columns=['observation_count'],inplace=True)\n",
        "\n",
        "else:\n",
        "    print('Missing file_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZGIGeQIdW3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ebird_ss=reduce_mem_usage(ebird_ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HksvjPJX5LZ-",
        "colab_type": "text"
      },
      "source": [
        "## Set variables for climatic data comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYmozHd45Q62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables_climatic_long=[\n",
        " 'bio1', #Annual Mean Temperature\n",
        " 'bio4', #Temperature Seasonality (standard deviation ×100)\n",
        " 'bio12', #Annual Precipitation\n",
        " 'bio15', #Precipitation Seasonality (Coefficient of Variation)\n",
        " ]\n",
        "\n",
        "variables_effort=[\n",
        " 'time_observations_started',\n",
        " 'duration_minutes',\n",
        " 'effort_distance_km',\n",
        " 'number_observers',\n",
        "]\n",
        "\n",
        "variables_climatic_365=[\n",
        " 'prec365_mean',\n",
        " 'tmp365_mean',       \n",
        " 'tmp365_std',\n",
        " 'prec365_cv',]\n",
        "              \n",
        "variables_climatic_730=[\n",
        " 'prec730_mean',\n",
        " 'tmp730_mean',\n",
        " 'tmp730_std',                         \n",
        " 'prec730_cv',]            \n",
        "\n",
        "variables_climatic_1095=[\n",
        " 'prec1095_mean',\n",
        " 'tmp1095_mean',\n",
        " 'tmp1095_std',\n",
        " 'prec1095_cv',]\n",
        "           \n",
        "variables_climatic_1460=[\n",
        " 'prec1460_mean',\n",
        " 'tmp1460_mean',\n",
        " 'tmp1460_std',\n",
        " 'prec1460_cv',]\n",
        "                          \n",
        "variables_climatic_1825=[                                          \n",
        " 'prec1825_mean',\n",
        " 'tmp1825_mean',\n",
        " 'tmp1825_std',\n",
        " 'prec1825_cv',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ls-oEZ55G6m",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T97nvIRlvXD_",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwx5HjufvJBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "params={'n_estimators':100,\n",
        "        'random_state':0,\n",
        "        'verbose':0,\n",
        "        'n_jobs':-1,\n",
        "        'class_weight':'balanced_subsample',\n",
        "        'max_samples':0.1,\n",
        "}\n",
        "\n",
        "\n",
        "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=72).split(ebird_ss, ebird_ss[['species_observed']]))\n",
        "\n",
        "variables_list=[['species_observed']+variables_effort,\n",
        "                ['species_observed']+variables_climatic_long+variables_effort,\n",
        "                ['species_observed']+variables_effort+variables_climatic_365,\n",
        "                ['species_observed']+variables_effort+variables_climatic_730,\n",
        "                ['species_observed']+variables_effort+variables_climatic_1095,\n",
        "                ['species_observed']+variables_effort+variables_climatic_1460,\n",
        "                ['species_observed']+variables_effort+variables_climatic_1825,\n",
        "               ]\n",
        "\n",
        "variables_labels=['effort','effort + 30 years climatic average',\n",
        "                 'effort + 1 year climatic average',\n",
        "                 'effort + 2 year climatic average',\n",
        "                 'effort + 3 year climatic average',\n",
        "                 'effort + 4 year climatic average',\n",
        "                 'effort + 5 year climatic average',\n",
        "                 ]\n",
        "\n",
        "df_RF_ls_ls=[]\n",
        "for i, (train_idx, test_idx) in enumerate(splits):\n",
        "    print(f'=====Start {i+1}-fold=====')\n",
        "    df_RF_ls=[]\n",
        "    for j,(variables,label) in enumerate(zip(variables_list,variables_labels)):\n",
        "        \n",
        "        train_x = ebird_ss.iloc[train_idx,:]\n",
        "        test_x = ebird_ss.iloc[test_idx,:]\n",
        "\n",
        "        train_x=train_x[variables]\n",
        "        test_x=test_x[variables]\n",
        "\n",
        "        train_X=train_x[variables[1:]]\n",
        "        train_y=train_x['species_observed']\n",
        "        test_X=test_x[variables[1:]]\n",
        "        test_y=test_x['species_observed']\n",
        "\n",
        "        defa2 = RandomForestClassifier(**params)\n",
        "        defa2.fit(train_X.values, train_y.values)\n",
        "\n",
        "        pred = defa2.predict_proba(test_X.values)\n",
        "        tmp1=pd.DataFrame(pred,columns=[\"absence\",\"prediction\"]).drop(columns='absence')\n",
        "        tmp2=pd.DataFrame(test_y.values.reshape(-1,1),columns=['Actual']).astype(int)\n",
        "        df_RF=pd.concat([tmp1,tmp2],axis=1)\n",
        "        df_RF_ls.append(df_RF)\n",
        "\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(df_RF.Actual.values,df_RF.prediction.values, pos_label=None)\n",
        "        print(f'AUC of {label} variables:{metrics.auc(fpr, tpr):.4f}')\n",
        "        \n",
        "    df_RF_ls_ls.append(df_RF_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIGwoTTYzu-k",
        "colab_type": "text"
      },
      "source": [
        "## Preparation fpr the comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9myfFoWzzrDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_converted=pd.DataFrame(df_RF_ls_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4MjuoH8zrH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for j in range(7):\n",
        "    for i in range(5):\n",
        "        if i==0:\n",
        "            new=pd.concat([df_converted.iloc[i,j].prediction])\n",
        "        else:\n",
        "            new=pd.concat([new,df_converted.iloc[i,j].prediction])\n",
        "    new.reset_index(inplace=True, drop=True)\n",
        "    if j==0:\n",
        "        base=pd.DataFrame(new)\n",
        "    else:\n",
        "        base = pd.concat([base, new], axis=1)\n",
        "        \n",
        "for i in range(5):\n",
        "    if i==0:\n",
        "        new=pd.concat([df_converted.iloc[i,j].Actual])\n",
        "    else:\n",
        "        new=pd.concat([new,df_converted.iloc[i,j].Actual])\n",
        "new.reset_index(inplace=True, drop=True)\n",
        "base = pd.concat([base, new], axis=1)\n",
        "base.columns=['effort','effort+30y','effort+1y','effort+2y','effort+3y','effort+4y','effort+5y','Actual']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BucKeZ06z6uj",
        "colab_type": "text"
      },
      "source": [
        "## Compare the AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj-Br5DozrM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUC_ls=[]\n",
        "for i in base.columns[:-1]:\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(base.Actual.values,base.loc[:,i].values, pos_label=None)\n",
        "    AUC=metrics.auc(fpr, tpr)\n",
        "    AUC_ls.append(AUC)\n",
        "    print(f'AUC of {i}: {AUC:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9VRFThozrVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax=plt.subplots(1,figsize=(5,4))\n",
        "plt.bar(base.columns[:-1],AUC_ls,color=('C0','C1','C2','C3','C4','C5','C6'))\n",
        "plt.xlabel('variables',size=12)\n",
        "plt.ylabel('AUC',size=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim([0.5,1.0])\n",
        "for index, value in enumerate(AUC_ls):\n",
        "    plt.text(index-0.45,value+0.005, str(np.round(value,3)),size=12)\n",
        "fig.savefig(f'clm_comparison_AUC_{file_id}.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg6ZbgJi0GmF",
        "colab_type": "text"
      },
      "source": [
        "## Compare the calibration plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH0A1mps0G-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,axes=plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "for label in base.columns[:-1]:\n",
        "    rf_obs=base.Actual.values.astype(float)\n",
        "    rf_pred=base[label].values\n",
        "\n",
        "    bin=0.05\n",
        "    df_calib=pd.DataFrame([pd.cut(rf_pred, bins=np.arange(0,1+bin,bin),include_lowest=True),rf_obs],\n",
        "                        columns=('prediction','observed'))\n",
        "\n",
        "    scatter=axes[0].scatter(np.arange(bin/2,1.00+bin/2,bin),\n",
        "            df_calib.groupby('prediction').mean()['observed'].values,\n",
        "                alpha=0.5,label=label)\n",
        "\n",
        "    axes[0].set_xlabel('Predicted encounter rate')\n",
        "    axes[0].set_ylabel('Observed encounter rate')\n",
        "    axes[0].set_title(f'Calibration plot (group size = {bin})')\n",
        "    axes[0].plot([0,1],[0,1],'k--')\n",
        "\n",
        "\n",
        "    bin=0.02\n",
        "    df_calib=pd.DataFrame([pd.cut(rf_pred, bins=np.arange(0,1+bin,bin),include_lowest=False),rf_obs],\n",
        "                        columns=('prediction','observed'))\n",
        "\n",
        "    scatter=axes[1].scatter(np.arange(bin/2,1.00+bin/2,bin),\n",
        "            df_calib.groupby('prediction').mean()['observed'].values,\n",
        "                alpha=0.5,label=label)\n",
        "    axes[1].set_xlabel('Predicted encounter rate')\n",
        "    axes[1].set_ylabel('Observed encounter rate')\n",
        "    axes[1].set_title(f'Calibration plot (group size = {bin})')\n",
        "    axes[1].plot([0,1],[0,1],'k--')\n",
        "\n",
        "    axes[2].plot(np.arange(bin/2,1.00+bin/2,bin),\n",
        "                df_calib['prediction'].value_counts(normalize=True).sort_index().values,alpha=0.5,marker=\"*\",label=label)\n",
        "    axes[2].set_xlabel('Predicted encounter rate')\n",
        "    axes[2].set_ylabel('Frequency (percentage)')\n",
        "    axes[2].set_title(f'Distribution of the prediction (group size = {bin})')\n",
        "\n",
        "    axes[0].legend(loc='best')\n",
        "    axes[1].legend(loc='best')\n",
        "    axes[2].legend(loc='best')\n",
        "fig.savefig(f'clm_comparison_calib_{file_id}.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}