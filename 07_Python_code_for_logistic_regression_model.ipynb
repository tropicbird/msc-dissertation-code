{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_Python_code_for_logistic_regression_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hgGZaPy9vA2e"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wyUOIo2vvA3c",
        "colab": {}
      },
      "source": [
        "import datetime as dt  # Python standard library datetime  module\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from tqdm import tqdm_notebook\n",
        "import pickle\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import gc\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from collections import Counter#<---value count for list\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MS-L5JZVvA3l",
        "colab": {}
      },
      "source": [
        "#Select the target species\n",
        "file_id=\"nutwoo\"\n",
        "bird_name=\"Nuttall's Woodpecker\"\n",
        "bcr_id='32'\n",
        "\n",
        "file_id=\"recwoo\"\n",
        "bird_name=\"Red-cockaded Woodpecker\"\n",
        "bcr_id='27'\n",
        "\n",
        "file_id=\"lewwoo\"\n",
        "bird_name=\"Lewisâ€™s Woodpecker\"\n",
        "bcr_id='9 and 10'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WjAs-1HgvA3t",
        "colab": {}
      },
      "source": [
        "PATH='/content/drive/My Drive/Colab Notebooks/dissertation/'\n",
        "ebird_ss=pd.read_csv(PATH+'ebird_ss_'+file_id+'_add30yMonth.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVhFnX0veORO",
        "colab_type": "text"
      },
      "source": [
        "## Define useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GrUf85ygvNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        if col != 'time':\n",
        "            col_type = df[col].dtypes\n",
        "            if col_type in numerics:\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)  \n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3nm7MrdKib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "def plot_confusion_matrix(cm,\n",
        "                          classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix very prettily.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(3, 3))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Specify the tick marks and axis text\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=0)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    # The data formatting\n",
        "    fmt = '.2f' if normalize else 'd'# t <--- Is this t typo??\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    # Print the text of the matrix, adjusting text colour for display\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_VTWHcadKui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "def Find_Optimal_Cutoff(target, predicted):\n",
        "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
        "    Parameters\n",
        "    ----------\n",
        "    target : Matrix with dependent or target data, where rows are observations\n",
        "\n",
        "    predicted : Matrix with predicted data, where rows are observations\n",
        "\n",
        "    Returns\n",
        "    -------     \n",
        "    list type, with optimal cutoff value\n",
        "    (Source: https://stackoverflow.com/questions/56203889/how-to-get-the-optimal-threshold-from-roc-curve-in-python)   \n",
        "    \"\"\"\n",
        "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
        "    i = np.arange(len(tpr)) \n",
        "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
        "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
        "\n",
        "    return list(roc_t['threshold']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXcWTX1Ca_h",
        "colab_type": "text"
      },
      "source": [
        "## Drop/fix NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcGpJalcCH7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check\n",
        "print((ebird_ss.isna().describe().loc['unique']==2).sort_values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBhusA17CNv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if file_id==\"nutwoo\":\n",
        "    # For Nuttall's Woodpecker\n",
        "    print(ebird_ss.prec30_cv.isna().value_counts())\n",
        "    print(ebird_ss.prec180_cv.isna().value_counts())\n",
        "    print(ebird_ss.observation_count.isna().value_counts())\n",
        "    ebird_ss.loc[ebird_ss['prec30_cv'].isna(),'prec30_cv']=0\n",
        "    ebird_ss.loc[ebird_ss['prec180_cv'].isna(),'prec180_cv']=0\n",
        "    ebird_ss.drop(columns=['observation_count'],inplace=True)\n",
        "\n",
        "elif file_id==\"recwoo\":\n",
        "    # For \"Red-cockaded Woodpecker\"\n",
        "    print(ebird_ss.prec30_cv.isna().value_counts())\n",
        "    print(ebird_ss.elevation_median.isna().value_counts())\n",
        "    print(ebird_ss.elevation_sd.isna().value_counts())\n",
        "    print(ebird_ss.observation_count.isna().value_counts())\n",
        "    ebird_ss.drop(columns=['observation_count'],inplace=True)\n",
        "    ebird_ss.dropna(inplace=True)\n",
        "    ebird_ss.reset_index(drop=True,inplace=True)\n",
        "\n",
        "elif file_id==\"lewwoo\":\n",
        "    # For \"Lewisâ€™s Woodpecker\"\n",
        "    print(ebird_ss.prec30_cv.isna().value_counts())\n",
        "    print(ebird_ss.observation_count.isna().value_counts())\n",
        "    ebird_ss.loc[ebird_ss['prec30_cv'].isna(),'prec30_cv']=0\n",
        "    ebird_ss.drop(columns=['observation_count'],inplace=True)\n",
        "\n",
        "else:\n",
        "    print('Missing file_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZGIGeQIdW3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ebird_ss=reduce_mem_usage(ebird_ss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HksvjPJX5LZ-",
        "colab_type": "text"
      },
      "source": [
        "## Set variables for use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYmozHd45Q62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables_base=['species_observed',\n",
        "'time_observations_started',\n",
        "'duration_minutes',\n",
        "'effort_distance_km',\n",
        " 'number_observers',\n",
        " 'bio1',\n",
        " 'bio2',\n",
        " 'bio3',\n",
        " 'bio4',\n",
        " 'bio5',\n",
        " 'bio6',\n",
        " 'bio7',\n",
        " 'bio8',\n",
        " 'bio9',\n",
        " 'bio10',\n",
        " 'bio11',\n",
        " 'bio12',\n",
        " 'bio13',\n",
        " 'bio14',\n",
        " 'bio15',\n",
        " 'bio16',\n",
        " 'bio17',\n",
        " 'bio18',\n",
        " 'bio19',\n",
        " 'prec30_mean',\n",
        " 'prec180_mean',\n",
        " 'prec365_mean',\n",
        " 'prec730_mean',\n",
        " 'prec1095_mean',\n",
        " 'prec1460_mean',\n",
        " 'prec1825_mean',\n",
        " 'tmp30_mean',\n",
        " 'tmp30_std',\n",
        " 'tmp180_mean',\n",
        " 'tmp180_std',\n",
        " 'tmp365_mean',\n",
        " 'tmp365_std',\n",
        " 'tmp730_mean',\n",
        " 'tmp730_std',\n",
        " 'tmp1095_mean',\n",
        " 'tmp1095_std',\n",
        " 'tmp1460_mean',\n",
        " 'tmp1460_std',\n",
        " 'tmp1825_mean',\n",
        " 'tmp1825_std',\n",
        " 'tmax30_mean',\n",
        " 'tmax30_std',\n",
        " 'tmax180_mean',\n",
        " 'tmax180_std',\n",
        " 'tmax365_mean',\n",
        " 'tmax365_std',\n",
        " 'tmax730_mean',\n",
        " 'tmax730_std',\n",
        " 'tmax1095_mean',\n",
        " 'tmax1095_std',\n",
        " 'tmax1460_mean',\n",
        " 'tmax1460_std',\n",
        " 'tmax1825_mean',\n",
        " 'tmax1825_std',\n",
        " 'tmin30_mean',\n",
        " 'tmin30_std',\n",
        " 'tmin180_mean',\n",
        " 'tmin180_std',\n",
        " 'tmin365_mean',\n",
        " 'tmin365_std',\n",
        " 'tmin730_mean',\n",
        " 'tmin730_std',\n",
        " 'tmin1095_mean',\n",
        " 'tmin1095_std',\n",
        " 'tmin1460_mean',\n",
        " 'tmin1460_std',\n",
        " 'tmin1825_mean',\n",
        " 'tmin1825_std',\n",
        " 'prec30_cv',\n",
        " 'prec180_cv',\n",
        " 'prec365_cv',\n",
        " 'prec730_cv',\n",
        " 'prec1095_cv',\n",
        " 'prec1460_cv',\n",
        " 'prec1825_cv',\n",
        " 'tmin_30y_monthly',\n",
        " 'tmax_30y_monthly',\n",
        " 'tavg_30y_monthly',\n",
        " 'prec_30y_monthly',\n",
        " 'srad_30y_monthly',\n",
        " 'wind_30y_monthly',\n",
        " 'vapr_30y_monthly',\n",
        " 'pland_00_water',\n",
        " 'pland_01_evergreen_needleleaf',\n",
        " 'pland_02_evergreen_broadleaf',\n",
        " 'pland_03_deciduous_needleleaf',#<--remove for nutwoo\n",
        " 'pland_04_deciduous_broadleaf',\n",
        " 'pland_05_mixed_forest',\n",
        " 'pland_06_closed_shrubland',\n",
        " 'pland_07_open_shrubland',\n",
        " 'pland_08_woody_savanna',\n",
        " 'pland_09_savanna',\n",
        " 'pland_10_grassland',\n",
        " 'pland_11_wetland',\n",
        " 'pland_12_cropland',\n",
        " 'pland_13_urban',\n",
        " 'pland_14_mosiac',\n",
        " 'pland_15_barren',\n",
        "'elevation_median',\n",
        "'elevation_sd'\n",
        "]\n",
        "if file_id==\"nutwoo\":\n",
        "    variables_base.remove('pland_03_deciduous_needleleaf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2HViiqhW2h5",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esXhw5pkoG3M",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue1rZWuOW609",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=72).split(ebird_ss, ebird_ss[['species_observed']]))\n",
        "\n",
        "result_ls=[]\n",
        "glm_obs_ls=[]\n",
        "glm_pred_ls=[]\n",
        "\n",
        "for i, (train_idx, test_idx) in enumerate(splits):\n",
        "    variables=variables_base.copy()\n",
        "\n",
        "    train_x = ebird_ss.iloc[train_idx,:]\n",
        "    test_x = ebird_ss.iloc[test_idx,:]\n",
        "    train_x=train_x[variables]\n",
        "    test_x=test_x[variables]\n",
        "\n",
        "    print(f'=====Start {i+1}-fold=====')\n",
        "    print(f'len of variables {len(variables)}')\n",
        "\n",
        "    str_tmp=\"\"\n",
        "    for variable in variables[1:]:\n",
        "        str_tmp=str_tmp+\"+\"+variable\n",
        "    formula =\"species_observed ~ \"+str_tmp[1:]\n",
        "    family = sm.families.Binomial()\n",
        "    model = smf.glm(formula=formula, data=train_x.astype(float), family=family)\n",
        "    result=model.fit()\n",
        "\n",
        "    pred_glm=result.predict(test_x.sort_values('species_observed').drop('species_observed',axis=1))\n",
        "    glm_obs=test_x.sort_values('species_observed').astype(float)['species_observed'].values\n",
        "    glm_pred=pred_glm.values\n",
        "\n",
        "    glm_obs_ls.append(glm_obs)\n",
        "    glm_pred_ls.append(glm_pred)\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(glm_obs,glm_pred, pos_label=None)\n",
        "    print(f'AUC: {metrics.auc(fpr, tpr):0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68jTYqa0adSI",
        "colab_type": "text"
      },
      "source": [
        "## Show ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKodbvBqawqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,ax=plt.subplots(1,figsize=(5,4))\n",
        "AUC_ls=[]\n",
        "for i, (glm_obs, glm_pred) in enumerate(zip(glm_obs_ls,glm_pred_ls)):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(glm_obs,glm_pred, pos_label=None)\n",
        "    print(f'AUC of valid data:{metrics.auc(fpr, tpr):0.4f}')\n",
        "\n",
        "    plt.plot([0,1],[0,1],'k--')\n",
        "    auc_val=str(round(metrics.auc(fpr, tpr),3)).ljust(5, '0')\n",
        "    AUC_ls.append(metrics.auc(fpr, tpr))\n",
        "    plt.plot(fpr,tpr,label=f'[AUC={auc_val}] {i+1}-fold')\n",
        "    plt.xlabel('False positive rate (1-specificity)')\n",
        "    plt.ylabel('True positive rate (sensitivity)')\n",
        "    plt.title('ROC curve')\n",
        "\n",
        "print(f'Mean: {np.mean(AUC_ls):0.4f}')\n",
        "print(f'SD: {np.std(AUC_ls):0.4f}')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "fig.savefig(PATH+f'figures/glm_all_vari_AUC_{file_id}.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5WlUofMahDC",
        "colab_type": "text"
      },
      "source": [
        "## Sensitivity, Specificity, threshold, confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsw-HOgKa9Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sensitivity_ls=[]\n",
        "specificity_ls=[]\n",
        "threshold_ls=[]\n",
        "\n",
        "for i, (glm_obs, glm_pred) in enumerate(zip(glm_obs_ls,glm_pred_ls)):\n",
        "    threshold = Find_Optimal_Cutoff(glm_obs,glm_pred)\n",
        "    print(f'threshold: {np.round(threshold[0],3)}')\n",
        "    glm_pred_disc=glm_pred>threshold[0]\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(glm_obs,glm_pred_disc,labels=[1,0])\n",
        "\n",
        "    sensitivity1 = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "    sensitivity_ls.append(sensitivity1)\n",
        "    print('Sensitivity : ', np.round(sensitivity1,3) )\n",
        "\n",
        "    specificity1 = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    specificity_ls.append(specificity1)\n",
        "    print('Specificity : ', np.round(specificity1,3))\n",
        "    print(f'{np.round(sensitivity1,3)}&{np.round(specificity1,3)}&{np.round(threshold[0],3)}')\n",
        "\n",
        "    threshold_ls.append(threshold[0])\n",
        "\n",
        "    classes=['True','False']\n",
        "    plot_confusion_matrix(cm,classes,normalize=False)\n",
        "    \n",
        "    if i==0:\n",
        "        #pass\n",
        "        plt.savefig(PATH+f'figures/glm_all_vari_cm_{file_id}_{i+1}_fold.png',bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print('Mean')\n",
        "print(f'Sensitivity: {np.mean(sensitivity_ls):0.4f}')\n",
        "print(f'Specificity: {np.mean(specificity_ls):0.4f}')\n",
        "print(f'Threshold: {np.mean(threshold_ls):0.4f}')\n",
        "\n",
        "print('SD')\n",
        "print(f'Sensitivity: {np.std(sensitivity_ls):0.4f}')\n",
        "print(f'Specificity: {np.std(specificity_ls):0.4f}')\n",
        "print(f'Threshold: {np.std(threshold_ls):0.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PxQ4X27ahJL",
        "colab_type": "text"
      },
      "source": [
        "## Calibration plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QesDW0sEaxhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,axes=plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "for i, (glm_obs, glm_pred) in enumerate(zip(glm_obs_ls,glm_pred_ls)):\n",
        "\n",
        "    bin=0.05\n",
        "    df_calib=pd.DataFrame([pd.cut(glm_pred, bins=np.arange(0,1+bin,bin),include_lowest=False),glm_obs],\n",
        "                        columns=('prediction','observed'))\n",
        "    \n",
        "    scatter=axes[0].scatter(np.arange(bin/2,1.00+bin/2,bin),\n",
        "            df_calib.groupby('prediction').mean()['observed'].values,\n",
        "                alpha=0.5,label=f'{i+1}-fold')\n",
        "    axes[0].set_xlabel('Predicted encounter rate')\n",
        "    axes[0].set_ylabel('Observed encounter rate')\n",
        "    axes[0].set_title(f'Calibration plot (group size = {bin})')\n",
        "    axes[0].plot([0,1],[0,1],'k--')\n",
        "\n",
        "    bin=0.02\n",
        "    df_calib=pd.DataFrame([pd.cut(glm_pred, bins=np.arange(0,1+bin,bin),include_lowest=False),glm_obs],\n",
        "                        columns=('prediction','observed'))\n",
        "\n",
        "    scatter=axes[1].scatter(np.arange(bin/2,1.00+bin/2,bin),\n",
        "            df_calib.groupby('prediction').mean()['observed'].values,\n",
        "                alpha=0.5,label=f'{i+1}-fold')\n",
        "    axes[1].set_xlabel('Predicted encounter rate')\n",
        "    axes[1].set_ylabel('Observed encounter rate')\n",
        "    axes[1].set_title(f'Calibration plot (group size = {bin})')\n",
        "    axes[1].plot([0,1],[0,1],'k--')\n",
        "\n",
        "    axes[2].plot(np.arange(bin/2,1.00+bin/2,bin),\n",
        "                df_calib['prediction'].value_counts(normalize=True).sort_index().values,alpha=0.5,marker=\"*\",label=f'{i+1}-fold')\n",
        "    axes[2].set_xlabel('Predicted encounter rate')\n",
        "    axes[2].set_ylabel('Frequency (percentage)')\n",
        "    axes[2].set_title(f'Distribution of the prediction (group size = {bin})')\n",
        "\n",
        "axes[0].legend(loc='best')\n",
        "axes[1].legend(loc='best')\n",
        "axes[2].legend(loc='best')\n",
        "fig.savefig(PATH+f'figures/glm_all_vari_calib_all_{file_id}.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}